{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A total of 30 cases of which 6 are positive.  \n",
    "A prediction of 7 positive cases.  \n",
    "There are 2 false positives (Type I error).  \n",
    "There is 1 false negative (Type II error).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y     = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "y_hat = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion_matrix function in sklearn returns a matrix in the following format.  \n",
    "The predicted states in columns : left for negative; right for positive.  \n",
    "The actual states in rows : top for negative; bottom for positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      " [[22  2]\n",
      " [ 1  5]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix :\\n\", confusion_matrix(y, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personally, I prefer to put the positive states (actual and predicted) in the upper left corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      " [[ 5  2]\n",
      " [ 1 22]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y, y_hat).T\n",
    "cm = np.flip(cm, 0)\n",
    "cm = np.flip(cm, 1)\n",
    "print(\"Confusion Matrix :\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/basilhan/figures/blob/master/Precision.png?raw=true\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.714\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision : %.3f\" % precision_score(y, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/basilhan/figures/blob/master/Recall.png?raw=true\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall : 0.833\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall : %.3f\" % recall_score(y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score : 0.769\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score : %.3f\" % f1_score(y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.92      0.94        24\n",
      "          1       0.71      0.83      0.77         6\n",
      "\n",
      "avg / total       0.91      0.90      0.90        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y, y_hat)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permalink : https://nbviewer.jupyter.org/github/basilhan/ml-in-action/blob/master/PythonClassificationMetrics.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
